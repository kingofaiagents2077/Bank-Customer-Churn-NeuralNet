{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoO7ROnuht51"
   },
   "source": [
    "<center><font size=6> Bank Churn Prediction </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q__obHNhdHtV"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSyQJZSAaPA3"
   },
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJQ5k8umdJdN"
   },
   "source": [
    "Businesses like banks which provide service have to worry about problem of 'Customer Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a customer's decision in this regard. Management can concentrate efforts on improvement of service, keeping in mind these priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s749lpTNaRkN"
   },
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbrLMQQ6dKQU"
   },
   "source": [
    "You as a Data scientist with the  bank need to  build a neural network based classifier that can determine whether a customer will leave the bank  or not in the next 6 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tsb28swdaVAs"
   },
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mquomUwdMol"
   },
   "source": [
    "* CustomerId: Unique ID which is assigned to each customer\n",
    "\n",
    "* Surname: Last name of the customer\n",
    "\n",
    "* CreditScore: It defines the credit history of the customer.\n",
    "  \n",
    "* Geography: A customer’s location\n",
    "   \n",
    "* Gender: It defines the Gender of the customer\n",
    "   \n",
    "* Age: Age of the customer\n",
    "    \n",
    "* Tenure: Number of years for which the customer has been with the bank\n",
    "\n",
    "* NumOfProducts: refers to the number of products that a customer has purchased through the bank.\n",
    "\n",
    "* Balance: Account balance\n",
    "\n",
    "* HasCrCard: It is a categorical variable which decides whether the customer has credit card or not.\n",
    "\n",
    "* EstimatedSalary: Estimated salary\n",
    "\n",
    "* isActiveMember: Is is a categorical variable which decides whether the customer is active member of the bank or not ( Active member in the sense, using bank products regularly, making transactions etc )\n",
    "\n",
    "* Exited : whether or not the customer left the bank within six month. It can take two values\n",
    "** 0=No ( Customer did not leave the bank )\n",
    "** 1=Yes ( Customer left the bank )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyTYkHrRc0kz"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHHrSIl4c6Yn"
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MPLBACKEND'] = 'TkAgg'  # or 'Agg'\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from scipy import stats \n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential  # Use this one from TensorFlow\n",
    "from tensorflow.keras.layers import Dense, Input  # Use these from TensorFlow\n",
    "from tensorflow.keras.optimizers import SGD, Adam  # Optimizers from TensorFlow\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from keras_tuner import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier  # Use this for KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(keras.__version__)  # Should print the version of Keras included in TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7ubXtC8HUOA"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xGZLJmZUdkPq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Nobody\\\\Downloads\\\\school stuff\\\\Bank Churn Prediction\\\\bank-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a duplicate copy of data\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRxrJ2MHd_Sf"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4sPbCEoLuQBk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "i need to conduct a observations, and sanity check.\n",
    "\n",
    "check out he first few rows\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W036jsgwRdVN"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSFkV8KJiZSv"
   },
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g1Lxry70ibDw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# descriptive statistics \n",
    "univariate_desc_stats = df.describe()\n",
    "print(univariate_desc_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nRowNumber- there are 10,000 rows, which means 10,000 cusotmer records \\n\\nCustomerID- identifier for unique customers which is 10,000 entries\\n\\nCreditScore- the average credit score is 650.53.\\nthe lowest credit score is 350.\\nthe highest Credit Score is 850.\\n25% of customers have a credit score below 584.\\n75% of customers have a credit score above 718.\\n\\nAge- the average age of the customer is about 39 years old.\\nthe youngest customer age is 18 years old.\\nthe oldest customer age is 92 years old . \\n25% of customers are younger than 32 years old.\\n25% of cusomters are older than 44.\\n\\nTenure(The length of time an account is open)\\nthe average number of years a customer has been with the bank ,\\nis around 5 years. \\nmin is 0, which indicates some have just joined the bank.\\nthe maximum tenure is 10 years . \\n25% of cusomter have in with the bank for 3 years or less.\\n75% of customer have been with the bank for 7 years or more \\n\\nBalance(account balance)\\nThe average customer's account balance is $76,485\\nmin is 0 , telling us that someone has a balance of $0 and ,\\ndoesn't keep any money in the account or rely on credit products.\\nThe highest account balance is #\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "RowNumber- there are 10,000 rows, which means 10,000 cusotmer records \n",
    "\n",
    "CustomerID- identifier for unique customers which is 10,000 entries\n",
    "\n",
    "CreditScore- the average credit score is 650.53.\n",
    "the lowest credit score is 350.\n",
    "the highest Credit Score is 850.\n",
    "25% of customers have a credit score below 584.\n",
    "75% of customers have a credit score above 718.\n",
    "\n",
    "Age- the average age of the customer is about 39 years old.\n",
    "the youngest customer age is 18 years old.\n",
    "the oldest customer age is 92 years old . \n",
    "25% of customers are younger than 32 years old.\n",
    "25% of cusomters are older than 44.\n",
    "\n",
    "Tenure(The length of time an account is open)\n",
    "the average number of years a customer has been with the bank ,\n",
    "is around 5 years. \n",
    "min is 0, which indicates some have just joined the bank.\n",
    "the maximum tenure is 10 years . \n",
    "25% of cusomter have in with the bank for 3 years or less.\n",
    "75% of customer have been with the bank for 7 years or more \n",
    "\n",
    "Balance(account balance)\n",
    "The average customer's account balance is $76,485\n",
    "min is 0 , telling us that someone has a balance of $0 and ,\n",
    "doesn't keep any money in the account or rely on credit products.\n",
    "The highest account balance is #\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# frequencey tabe for categorical variables (example for 'Gender')\n",
    "print(df['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for numerical variables (e.g., Age)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df['Age'].values, bins=30, kde=True)\n",
    "plt.title('Distribution of Age')\n",
    "plt.savefig('AgeDistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nthe distribution peaks between 30's and 40's. Telling us that , most of our ,\\ncustomers are that age. There is also a gradual decline in the number as the,\\nage increases beyond 50.\\n\\nthe distribution has a slight right skew, there are fewer older customers,\\nin the 60's , 70's, and older, but they do have afew outliers in the 80's and \\n90's\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "the distribution peaks between 30's and 40's. Telling us that , most of our ,\n",
    "customers are that age. There is also a gradual decline in the number as the,\n",
    "age increases beyond 50.\n",
    "\n",
    "the distribution has a slight right skew, there are fewer older customers,\n",
    "in the 60's , 70's, and older, but they do have afew outliers in the 80's and \n",
    "90's\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for numerical variable (e.g., CreditScore)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(x=df['CreditScore'])\n",
    "plt.title('Boxplot of CreditScore')\n",
    "plt.savefig('CreditScoreBoxPlot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe median credit score is approximately 650 to 680, its a even 50/50 split\\n50% of customers have higher and lower scores.\\n\\nTHe whisker extensions are from approximately 400 to 850, low outliers suggest\\nnot that many customers whave poor credit scores. \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "the median credit score is approximately 650 to 680, its a even 50/50 split\n",
    "50% of customers have higher and lower scores.\n",
    "\n",
    "THe whisker extensions are from approximately 400 to 850, low outliers suggest\n",
    "not that many customers whave poor credit scores. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Count of Customers by Geography')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bar plot for cateogrical variable(e.g., Geography)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='Geography', data=df)\n",
    "plt.title('Count of Customers by Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbased on the countplot most of our customers are in france\\nthen spain and germany. \\n\\nalmost 5000 customers in france\\n\\naround 2500 in spain and Germany\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "based on the countplot most of our customers are in france\n",
    "then spain and germany. \n",
    "\n",
    "almost 5000 customers in france\n",
    "\n",
    "around 2500 in spain and Germany\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot for continous variable (e.g., Balance)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.kdeplot(df['Balance'], fill=True)\n",
    "plt.title('Density Plot of Balance')\n",
    "plt.savefig('DensityPlotOFBalance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis densityy plot dipslys two peaks, for the Balance.\\n\\nPEak 1-the first peak is around a balance is of $0 , suggesting that, \\nthose customers dont,have that much money, or the money goes out as soon ,\\nas the money is deposited.\\n\\nBusiness Recommendations: the presense of a Large number of Customers with zero,\\nbalance. Might require further investigation, susceptibale to higher risk of leaving\\nbank. This group   situation , is possible opportunity. if the bank , decides to ,\\npromote finiancial services or products . \\n\\npeak 2 - the second peak is around $100,000 TO $150,000 . IT suggest  that this group,\\nhas a significant balance , that is customers with large deposits at a time. These ,\\ncustomers, might \\n\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "this densityy plot dipslys two peaks, for the Balance.\n",
    "\n",
    "PEak 1-the first peak is around a balance is of $0 , suggesting that, \n",
    "those customers dont,have that much money, or the money goes out as soon ,\n",
    "as the money is deposited.\n",
    "\n",
    "Business Recommendations: the presense of a Large number of Customers with zero,\n",
    "balance. Might require further investigation, susceptibale to higher risk of leaving\n",
    "bank. This group   situation , is possible opportunity. if the bank , decides to ,\n",
    "promote finiancial services or products . \n",
    "\n",
    "peak 2 - the second peak is around $100,000 TO $150,000 . IT suggest  that this group,\n",
    "has a significant balance , that is customers with large deposits at a time. These ,\n",
    "customers, might \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of Age: 1.0113202630234552\n",
      "Kurtosis of Age: 1.3953470615086956\n"
     ]
    }
   ],
   "source": [
    "# skewness and kurtosis (for numeric variables)\n",
    "print('Skewness of Age:', df['Age'].skew())\n",
    "print('Kurtosis of Age:', df['Age'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Skewness age of : 1.0113202630234552 means , its a slight positive skewed.\\nthe \"Age\" data,  will have a longer tail on the right side. which means \\nfew customers with higher ages that are pulling the distribution in that direction\\n\\nthe Kurtosis Age of : 1.40, if value is less than 3, which tells us it will have a \\nflatter peak compared to normal distribution.  it suggest that will be fewere extreme values.\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "The Skewness age of : 1.0113202630234552 means , its a slight positive skewed.\n",
    "the \"Age\" data,  will have a longer tail on the right side. which means \n",
    "few customers with higher ages that are pulling the distribution in that direction\n",
    "\n",
    "the Kurtosis Age of : 1.40, if value is less than 3, which tells us it will have a \n",
    "flatter peak compared to normal distribution.  it suggest that will be fewere extreme values.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles for Age:\n",
      "0.25    32.0\n",
      "0.50    37.0\n",
      "0.75    44.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# percentilies\n",
    "print('Percentiles for Age:')\n",
    "print(df['Age'].quantile([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n25th Percentile (Q1): 32 years\\nThis indicates that 25% of the customers are aged 32 or younger.\\nIt gives us a sense of where the lower quarter of the age distribution lies.\\n\\n50th Percentile (Median): 37 years\\n50% of customers,  are younger than 37 ,and 50% are older. \\nThis is a central tendency measure that divides the data into two equal parts.\\n\\n75th Percentile (Q3): 44 years\\n75% of the customers are aged 44 or younger. This tells us where the upper quarter,\\nof the age distribution lies. \\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "25th Percentile (Q1): 32 years\n",
    "This indicates that 25% of the customers are aged 32 or younger.\n",
    "It gives us a sense of where the lower quarter of the age distribution lies.\n",
    "\n",
    "50th Percentile (Median): 37 years\n",
    "50% of customers,  are younger than 37 ,and 50% are older. \n",
    "This is a central tendency measure that divides the data into two equal parts.\n",
    "\n",
    "75th Percentile (Q3): 44 years\n",
    "75% of the customers are aged 44 or younger. This tells us where the upper quarter,\n",
    "of the age distribution lies. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected using Z-score (|Z| > 3):\n",
      "Empty DataFrame\n",
      "Columns: [Balance]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# outlier detection using Z-score method (e.g., for 'Balance')\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df['Balance']))\n",
    "outliers_z = df[(z_scores > 3)]\n",
    "print(\"Outliers detected using Z-score (|Z| > 3):\")\n",
    "print(outliers_z[['Balance']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nused the Z-score method to identify potential outliers in \"Balance\" column. \\n\\nA Z-Score is  greater than 3 (or less than -3),\\ntypically indicates that a data point is an outlier.\\n\\nafter using the Z-score , i report there are no outliers detected,\\nin \"Balance\" column\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "used the Z-score method to identify potential outliers in \"Balance\" column. \n",
    "\n",
    "A Z-Score is  greater than 3 (or less than -3),\n",
    "typically indicates that a data point is an outlier.\n",
    "\n",
    "after using the Z-score , i report there are no outliers detected,\n",
    "in \"Balance\" column\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected using Z-score (|Z| > 3) for 'CreditScore':\n",
      "      CreditScore\n",
      "1405          359\n",
      "1631          350\n",
      "1838          350\n",
      "1962          358\n",
      "2473          351\n",
      "8723          350\n",
      "8762          350\n",
      "9624          350\n"
     ]
    }
   ],
   "source": [
    "# Z-score for 'Credit SCore'\n",
    "z_scores_credit = np.abs(stats.zscore(df['CreditScore']))\n",
    "outliers_credit = df[(z_scores_credit > 3)]\n",
    "print(\"Outliers detected using Z-score (|Z| > 3) for 'CreditScore':\")\n",
    "print(outliers_credit[['CreditScore']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(left column is the customer id, right column is the creditscore)\\n\\napplied Z-score to identify the outliers in \"CreditScore\" columns.\\nZ-score greater than 3 (or less than -3) , will be flagged as outliers\\n\\nthe result is , outliers were detected in \"CreditSCore\" variable, as listed below\\n\\nCreditScores: 359, 350, 350, 358, 351, 350, 350, 350 \\n(for customer IDs 1405, 1631, 1838, 1962, 2473, 8723, 8762, 9624)\\n\\n It is important to further investigate whether these outliers represent,\\n valid customer data or potential errors.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "(left column is the customer id, right column is the creditscore)\n",
    "\n",
    "applied Z-score to identify the outliers in \"CreditScore\" columns.\n",
    "Z-score greater than 3 (or less than -3) , will be flagged as outliers\n",
    "\n",
    "the result is , outliers were detected in \"CreditSCore\" variable, as listed below\n",
    "\n",
    "CreditScores: 359, 350, 350, 358, 351, 350, 350, 350 \n",
    "(for customer IDs 1405, 1631, 1838, 1962, 2473, 8723, 8762, 9624)\n",
    "\n",
    " It is important to further investigate whether these outliers represent,\n",
    " valid customer data or potential errors.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected using Z-score (|Z| > 3)  for 'Age':\n",
      "      Age\n",
      "85     75\n",
      "158    73\n",
      "230    72\n",
      "252    79\n",
      "310    80\n",
      "...   ...\n",
      "9646   71\n",
      "9671   78\n",
      "9736   78\n",
      "9894   77\n",
      "9936   77\n",
      "\n",
      "[133 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Z-Score for 'Age'\n",
    "z_scores_age = np.abs(stats.zscore(df['Age']))\n",
    "outliers_age = df[(z_scores_age > 3)]\n",
    "print(\"Outliers detected using Z-score (|Z| > 3)  for 'Age':\")\n",
    "print(outliers_age[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected using Z-score (|Z| > 3) for 'Tenure':\n",
      "Empty DataFrame\n",
      "Columns: [Tenure]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Z-score for 'Tenure'\n",
    "z_scores_tenure = np.abs(stats.zscore(df['Tenure']))\n",
    "outliers_tenure = df[(z_scores_tenure > 3)]\n",
    "print(\"Outliers detected using Z-score (|Z| > 3) for 'Tenure':\")\n",
    "print(outliers_tenure[['Tenure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected using Z-score (|Z| > 3) for 'Balance':\n",
      "Empty DataFrame\n",
      "Columns: [Balance]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Z-score for \"balance'\n",
    "z_scores_balance = np.abs(stats.zscore(df['Balance']))\n",
    "outliers_balance = df[(z_scores_balance > 3)]\n",
    "print(\"Outliers detected using Z-score (|Z| > 3) for 'Balance':\")\n",
    "print(outliers_balance[['Balance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected using Z-score (|Z| > 3)  for 'NumOfProducts':\n",
      "      NumOfProducts\n",
      "7                 4\n",
      "70                4\n",
      "1254              4\n",
      "1469              4\n",
      "1488              4\n",
      "1701              4\n",
      "1876              4\n",
      "2124              4\n",
      "2196              4\n",
      "2285              4\n",
      "2462              4\n",
      "2499              4\n",
      "2509              4\n",
      "2541              4\n",
      "2614              4\n",
      "2617              4\n",
      "2872              4\n",
      "3152              4\n",
      "3365              4\n",
      "3841              4\n",
      "4013              4\n",
      "4014              4\n",
      "4166              4\n",
      "4260              4\n",
      "4403              4\n",
      "4511              4\n",
      "4516              4\n",
      "4606              4\n",
      "4654              4\n",
      "4748              4\n",
      "4822              4\n",
      "5010              4\n",
      "5137              4\n",
      "5235              4\n",
      "5386              4\n",
      "5700              4\n",
      "5904              4\n",
      "6150              4\n",
      "6172              4\n",
      "6279              4\n",
      "6750              4\n",
      "6875              4\n",
      "7257              4\n",
      "7457              4\n",
      "7567              4\n",
      "7698              4\n",
      "7724              4\n",
      "7729              4\n",
      "8041              4\n",
      "8590              4\n",
      "8683              4\n",
      "8850              4\n",
      "8923              4\n",
      "9215              4\n",
      "9255              4\n",
      "9323              4\n",
      "9370              4\n",
      "9411              4\n",
      "9540              4\n",
      "9565              4\n"
     ]
    }
   ],
   "source": [
    "# Z-Score for 'NUmOfProducts\"\n",
    "z_scores_products = np.abs(stats.zscore(df['NumOfProducts']))\n",
    "outliers_products = df[(z_scores_products > 3)]\n",
    "print(\"Outliers detected using Z-score (|Z| > 3)  for 'NumOfProducts':\")\n",
    "print(outliers_products[['NumOfProducts']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in 'HasCrCard':\n",
      "Empty DataFrame\n",
      "Columns: [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
      "Index: []\n",
      "Outliers in 'IsActiveMember':\n",
      "Empty DataFrame\n",
      "Columns: [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# check for outliers in 'HasCrCard' and 'IsActiveMember'\n",
    "hascrcard_outliers = df[(df['HasCrCard'] != 0) & (df['HasCrCard'] != 1)]\n",
    "isactivemember_outliers = df[(df['IsActiveMember'] != 0) & (df['IsActiveMember'] != 1)]\n",
    "\n",
    "print(\"Outliers in 'HasCrCard':\")\n",
    "print(hascrcard_outliers)\n",
    "\n",
    "print(\"Outliers in 'IsActiveMember':\")\n",
    "print(isactivemember_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected using Z-score (|Z| > 3) for 'EstimatedSalary':\n",
      "Empty DataFrame\n",
      "Columns: [EstimatedSalary]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Z-Score for \"EstimatedSalary\"\n",
    "z_scores_salary = np.abs(stats.zscore(df['EstimatedSalary']))\n",
    "outliers_salary = df[(z_scores_salary > 3)]\n",
    "\n",
    "print(\"Outliers detected using Z-score (|Z| > 3) for 'EstimatedSalary':\")\n",
    "print(outliers_salary[['EstimatedSalary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlHTHF4glMxS"
   },
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "y_pKBXS9lLel"
   },
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculaate teh corretlation matrix for numeric columns only\n",
    "corr_matrix = numeric_df.corr() \n",
    "\n",
    "# plot the corrleation matrix \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=' .2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.savefig('CorrelationMatrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nexited (a customer who has left the bank )\\nchurn(when a customer stop using a bank's service or close account ) ,\\na.k.a customer attrition. \\n\\nage vs exited - there is a fair postive correalation of 0.29 ,\\na indication that when age increases, customers are more likely to exit(churn)\\n\\nBalance vs Exited - the correlation between balance and exited is 0.12, a slight ,\\n, positive , association . Customers with igher balance might be slightly prone\\nto churn\\n\\nIsActiveMember vs Exited - the correlation is -0.16, meaning that , more active a user,\\nis , the less likely to churn. Inactivity could be a significatant factor in ,\\ncustomer attrion.\\n\\nNumOfProducts vs. Exited - the correlations is -05, which is  a faint negative. \\nthe data suggests that if a customer has more products he might be less likely to \\nchurn, the effects will me mininimum.\\n\\n\\n\\nAge vs ISActiveMember: the corrleation is 0.09, a faint positive correlation. \\nwe can interpret , as Older customers may tend to be mroe active bank members\\n\\nKey takeways:\\nAge, Balance, and IsActiveMember appears to have the strongest correlations, with \\nExited. These variables can help us pedicting churn.\\n\\nCreditScore,NumOfProducts,andHasCrCard show a faint correlation with churn, \\nthey may not be as impactful in the model \\n\\n\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "exited (a customer who has left the bank )\n",
    "churn(when a customer stop using a bank's service or close account ) ,\n",
    "a.k.a customer attrition. \n",
    "\n",
    "age vs exited - there is a fair postive correalation of 0.29 ,\n",
    "a indication that when age increases, customers are more likely to exit(churn)\n",
    "\n",
    "Balance vs Exited - the correlation between balance and exited is 0.12, a slight ,\n",
    ", positive , association . Customers with igher balance might be slightly prone\n",
    "to churn\n",
    "\n",
    "IsActiveMember vs Exited - the correlation is -0.16, meaning that , more active a user,\n",
    "is , the less likely to churn. Inactivity could be a significatant factor in ,\n",
    "customer attrion.\n",
    "\n",
    "NumOfProducts vs. Exited - the correlations is -05, which is  a faint negative. \n",
    "the data suggests that if a customer has more products he might be less likely to \n",
    "churn, the effects will me mininimum.\n",
    "\n",
    "\n",
    "\n",
    "Age vs ISActiveMember: the corrleation is 0.09, a faint positive correlation. \n",
    "we can interpret , as Older customers may tend to be mroe active bank members\n",
    "\n",
    "Key takeways:\n",
    "Age, Balance, and IsActiveMember appears to have the strongest correlations, with \n",
    "Exited. These variables can help us pedicting churn.\n",
    "\n",
    "CreditScore,NumOfProducts,andHasCrCard show a faint correlation with churn, \n",
    "they may not be as impactful in the model \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical vs Numerical variables \n",
    "sns.scatterplot(x='Age', y='Balance', data=df, hue='Exited')\n",
    "plt.savefig('NumericalScatterPlot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBLUE EXITED(0) = with the bank\\n\\nORANGE EXITED(1) = EXITED (CHURN)\\n\\nLooks there are clustering of churned customers(oarnge), in the 40 to 60 range.\\nThis implies that customers in this age group are more likely to churn compared ,\\nto younger or older customers.\\n\\nIF you look (below 30), it appears younger customers are lower likely to exist.\\n(Its mostly Blue), while middle age customers , specificially between 45 and 60, \\nit appears more prone to exist(churn )\\n\\nHigh balance customers ($100,000) , appear to have a more big portion of orange dots,\\nindicating a higher likelihood of churn for rich invidiuals, in turn it supports the weak ,\\npositive correlation that higher-balance customers might be more likely to churn . \\n\\nconclusion- age and balance are important factors when predicting customer churn. \\nMiddle-aged customers, especially those with higher balances, should be monitored,\\nclosely as they may be at a higher risk of leaving.\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "BLUE EXITED(0) = with the bank\n",
    "\n",
    "ORANGE EXITED(1) = EXITED (CHURN)\n",
    "\n",
    "Looks there are clustering of churned customers(oarnge), in the 40 to 60 range.\n",
    "This implies that customers in this age group are more likely to churn compared ,\n",
    "to younger or older customers.\n",
    "\n",
    "IF you look (below 30), it appears younger customers are lower likely to exist.\n",
    "(Its mostly Blue), while middle age customers , specificially between 45 and 60, \n",
    "it appears more prone to exist(churn )\n",
    "\n",
    "High balance customers ($100,000) , appear to have a more big portion of orange dots,\n",
    "indicating a higher likelihood of churn for rich invidiuals, in turn it supports the weak ,\n",
    "positive correlation that higher-balance customers might be more likely to churn . \n",
    "\n",
    "conclusion- age and balance are important factors when predicting customer churn. \n",
    "Middle-aged customers, especially those with higher balances, should be monitored,\n",
    "closely as they may be at a higher risk of leaving.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair plot\n",
    "sns.pairplot(numeric_df)\n",
    "plt.savefig('PairPlot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif we look at features like age and balance, it shows distinct distributions.\\nage has a slightly right-skewed distribution, which tells us customers are younger,\\nwith fewer older customers.\\n\\nbalance distribution feature shows us it has another two peak(bi-modal) distrubition\\nlike the density plot earlier, Many customers have either very low balances (near $0),\\nor balances around $100,000 to $150,000.\\n\\nCreditScore shows a nearly normal distribution centered around 600 to 700.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if we look at features like age and balance, it shows distinct distributions.\n",
    "age has a slightly right-skewed distribution, which tells us customers are younger,\n",
    "with fewer older customers.\n",
    "\n",
    "balance distribution feature shows us it has another two peak(bi-modal) distrubition\n",
    "like the density plot earlier, Many customers have either very low balances (near $0),\n",
    "or balances around $100,000 to $150,000.\n",
    "\n",
    "CreditScore shows a nearly normal distribution centered around 600 to 700.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Exited</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>3404</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>4559</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Exited     0     1\n",
       "Gender            \n",
       "Female  3404  1139\n",
       "Male    4559   898"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df['Gender'], df['Exited'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nobservation: \\nfemale customers are more likely to churn, than  male customers.\\nThis could suggest that female customers might be experiencing something ,\\nthat makes them less satisfied or less loyal to the bank compared to male customers.\\nThe total number of male customers is higher than female customers in this dataset,\\nbut despite that, the absolute number of female churners (1139)\\nis still higher than male churners (898).\\n\\nactionable insight:\\nwe as the bank , might investigate reasons why female customers ,\\nare leaving at a higher rate. It could be helpful to examine, and find out\\nif its a specific  product, service, or experience that lead to there dissatisfaction.\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "observation: \n",
    "female customers are more likely to churn, than  male customers.\n",
    "This could suggest that female customers might be experiencing something ,\n",
    "that makes them less satisfied or less loyal to the bank compared to male customers.\n",
    "The total number of male customers is higher than female customers in this dataset,\n",
    "but despite that, the absolute number of female churners (1139)\n",
    "is still higher than male churners (898).\n",
    "\n",
    "actionable insight:\n",
    "we as the bank , might investigate reasons why female customers ,\n",
    "are leaving at a higher rate. It could be helpful to examine, and find out\n",
    "if its a specific  product, service, or experience that lead to there dissatisfaction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked bar plot\n",
    "pd.crosstab(df['Gender'], df['Exited']).plot(kind='bar', stacked=True)\n",
    "plt.title('Gender vs Exited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis stacked barplot is a visual representation of gender vs Exited graph above. \\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "this stacked barplot is a visual representation of gender vs Exited graph above. \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared: 112.91857062096116, p-value: 2.2482100097131755e-26\n"
     ]
    }
   ],
   "source": [
    "# using chi-square to test if the variables are indepedant \n",
    "crosstab = pd.crosstab(df['Gender'], df['Exited'])\n",
    "chi2, p, dof, expected = chi2_contingency(crosstab)\n",
    "print(f\"Chi-squared: {chi2}, p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe Chi-squared value is a measurment of how much the observed data deviates,\\nfrom the what we would expect if there was no relationship between the variable.\\n\\nwhich means a high Chi-squared value(112.91857062096116) indicates that the higher value,\\nthe greater the difference between observed and expected values.  There is  strong association,\\nbetween gender and churn in the data set.\\n\\nThis result supports the earlier findings from the cross-tabulation that gender,\\nhas a significant impact on churn. \\n\\n the relationship between gender and churn is statistically significant, \\n which means that gender plays a role in whether a customer decides to leave the bank.\\n\\n\\nactionable insight: \\nGiven the significance of gender in churn prediction, we as the bank may consider,\\ntargeted strategies to reduce churn among female customers, as they are more likely,\\nto leave based on previous findings.\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "the Chi-squared value is a measurment of how much the observed data deviates,\n",
    "from the what we would expect if there was no relationship between the variable.\n",
    "\n",
    "which means a high Chi-squared value(112.91857062096116) indicates that the higher value,\n",
    "the greater the difference between observed and expected values.  There is  strong association,\n",
    "between gender and churn in the data set.\n",
    "\n",
    "This result supports the earlier findings from the cross-tabulation that gender,\n",
    "has a significant impact on churn. \n",
    "\n",
    " the relationship between gender and churn is statistically significant, \n",
    " which means that gender plays a role in whether a customer decides to leave the bank.\n",
    "\n",
    "\n",
    "actionable insight: \n",
    "Given the significance of gender in churn prediction, we as the bank may consider,\n",
    "targeted strategies to reduce churn among female customers, as they are more likely,\n",
    "to leave based on previous findings.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot exited vs Balance\n",
    "sns.boxplot(x='Exited', y='Balance', data=df)\n",
    "plt.savefig('BoxPlotExitvsBalance.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe blue boxes show us customer balances - \\nbasically comparing the money in accounts of people who stayed with us ,\\nversus those who left.What\\'s interesting is that customers who left us,\\n(that\\'s the \"1\" on the bottom) actually had slightly more money in their accounts ,\\nabout $110,000 typically, compared to $90,000 for customers who stayed.\\n\\nThis tells me we should focus less on balance-related incentives ,\\nand more on other factors that might be causing these higher-balance customers to leave.\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "The blue boxes show us customer balances - \n",
    "basically comparing the money in accounts of people who stayed with us ,\n",
    "versus those who left.What's interesting is that customers who left us,\n",
    "(that's the \"1\" on the bottom) actually had slightly more money in their accounts ,\n",
    "about $110,000 typically, compared to $90,000 for customers who stayed.\n",
    "\n",
    "This tells me we should focus less on balance-related incentives ,\n",
    "and more on other factors that might be causing these higher-balance customers to leave.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot Exited Vs Age\n",
    "sns.barplot(x='Exited', y='Age', data=df)\n",
    "plt.savefig('ExitedVsAgeBarPlot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe graph shows us the average age of our customers who stayed versus those who left.\\nWhat jumps out is that customers who left us, (the \"1\" column) are typically older,\\naround 44 years old on average .Compared to customers who stayed with us, who average ,\\nabout 38 years old.This is really valuable information because it tells us we,\\nmight have an issue retaining our older customers. \\nBusiness Insight : \\nMaybe our services or products aren\\'t meeting their specific needs as well as they ,\\ncould be.We should consider looking at what features or services our older customers,\\nvalue most and whether we\\'re delivering on those expectations. Perhaps we need to,\\nenhance our customer experience for this demographic.\\n\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The graph shows us the average age of our customers who stayed versus those who left.\n",
    "What jumps out is that customers who left us, (the \"1\" column) are typically older,\n",
    "around 44 years old on average .Compared to customers who stayed with us, who average ,\n",
    "about 38 years old.This is really valuable information because it tells us we,\n",
    "might have an issue retaining our older customers. \n",
    "Business Insight : \n",
    "Maybe our services or products aren't meeting their specific needs as well as they ,\n",
    "could be.We should consider looking at what features or services our older customers,\n",
    "value most and whether we're delivering on those expectations. Perhaps we need to,\n",
    "enhance our customer experience for this demographic.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot geography vs exited\n",
    "sns.countplot(x='Geography', hue='Exited',data=df)\n",
    "plt.savefig('CountPlotGeorgraphyVSExit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ngraph shows us where our customers are located and whether they're staying with us,\\nor leaving.The blue bars show customers who've stayed, and the orange bars show those,\\nwho've left. Here's what stands out:\\n\\nFrance is our biggest market with over 4,000 customers who've stayed, \\nbut we're also seeing about 800 customers leaving.In Spain, we have around 2,000 loyal,\\ncustomers, and they seem to be our most satisfied group with the lowest number of departures - only about 400 customers leaving.\\nGermany has the smallest number of staying customers at about 1,700, but nearly 800,customers have left - which is almost the same number as France despite having a much smaller customer base.\\n\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "graph shows us where our customers are located and whether they're staying with us,\n",
    "or leaving.The blue bars show customers who've stayed, and the orange bars show those,\n",
    "who've left. Here's what stands out:\n",
    "\n",
    "France is our biggest market with over 4,000 customers who've stayed, \n",
    "but we're also seeing about 800 customers leaving.In Spain, we have around 2,000 loyal,\n",
    "customers, and they seem to be our most satisfied group with the lowest number of departures - only about 400 customers leaving.\n",
    "Germany has the smallest number of staying customers at about 1,700, but nearly 800,customers have left - which is almost the same number as France despite having a much smaller customer base.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab = pd.crosstab(df['Geography'], df['Exited'])\n",
    "sns.heatmap(crosstab, annot=True, cmap='Blues')\n",
    "plt.savefig('GeographyHeatMap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLooking at this heatmap:\\n\\nFrance has 4,200 staying customers (0) and 810 who left (1) - our largest market with moderate churn\\nGermany shows 1,700 staying customers and 810 who left - concerning high proportional loss\\nSpain has 2,100 staying customers and only 410 who left - our healthiest retention rate\\n\\nKey insight: Germany is losing customers at nearly twice the rate of France and Spain (32% vs 16% and 16%). This confirms our Germany market needs immediate attention, while Spain demonstrates our best retention practices.\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Looking at this heatmap:\n",
    "\n",
    "France has 4,200 staying customers (0) and 810 who left (1) - our largest market with moderate churn\n",
    "Germany shows 1,700 staying customers and 810 who left - concerning high proportional loss\n",
    "Spain has 2,100 staying customers and only 410 who left - our healthiest retention rate\n",
    "\n",
    "Key insight: Germany is losing customers at nearly twice the rate of France and Spain (32% vs 16% and 16%). This confirms our Germany market needs immediate attention, while Spain demonstrates our best retention practices.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal/time-based analysis\n",
    "sns.boxplot(x='Exited', y='Tenure', data=df)\n",
    "plt.title('Tenure vs Exited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
      "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
      "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUXPaUwZHUO8"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im defining a function to detect and treat outliers using IQR\n",
    "def treat_outliers_iqr(df, columns):\n",
    "    for col in columns:\n",
    "        # Calculate Q1 (25%) and Q3(75%)\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3-Q1\n",
    "\n",
    "        # im define bouns for Outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        #replacing outlieres with bounds\n",
    "        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing of numerical columns to check for outliers \n",
    "numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spllitting target (Exited) from predictors\n",
    "X = df.drop(columns=['Exited', 'Surname']) # Predictors (features)\n",
    "y = df['Exited'] #Target Variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nEEjgwleiMv"
   },
   "source": [
    "### Dummy Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "LJ19WoAYc6Yx"
   },
   "outputs": [],
   "source": [
    "# one- hot encoding categorical variables 'geography' and 'Gender'\n",
    "X_encoded = pd.get_dummies(X, columns=['Geography', 'Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgpx0xlSTlzN"
   },
   "source": [
    "### Train-validation-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split into train and test (70% train, 30% test)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Then, split the training data into train (70%) and validation (30%) from the original train set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlSyq5fNHUPp"
   },
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Outlier Treatment\n",
      "       CreditScore          Age       Tenure        Balance  NumOfProducts  \\\n",
      "count  4900.000000  4900.000000  4900.000000    4900.000000    4900.000000   \n",
      "mean    652.018163    38.870612     5.007755   76163.334218       1.532653   \n",
      "std      96.418548    10.454969     2.883168   62581.580333       0.587301   \n",
      "min     350.000000    18.000000     0.000000       0.000000       1.000000   \n",
      "25%     585.000000    32.000000     3.000000       0.000000       1.000000   \n",
      "50%     654.000000    37.000000     5.000000   95539.735000       1.000000   \n",
      "75%     719.000000    44.000000     7.000000  127900.490000       2.000000   \n",
      "max     850.000000    92.000000    10.000000  250898.090000       4.000000   \n",
      "\n",
      "       EstimatedSalary  \n",
      "count      4900.000000  \n",
      "mean     101179.728978  \n",
      "std       57482.040816  \n",
      "min          90.070000  \n",
      "25%       51978.417500  \n",
      "50%      101473.150000  \n",
      "75%      150684.552500  \n",
      "max      199970.740000  \n"
     ]
    }
   ],
   "source": [
    "# bdfore treatment (Display mean and std)\n",
    "print(\"Before Outlier Treatment\")\n",
    "print(X_train[numerical_features].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber            0\n",
      "CustomerId           0\n",
      "CreditScore          0\n",
      "Age                  0\n",
      "Tenure               0\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Geography_Germany    0\n",
      "Geography_Spain      0\n",
      "Gender_Male          0\n",
      "dtype: int64\n",
      "RowNumber            0\n",
      "CustomerId           0\n",
      "CreditScore          0\n",
      "Age                  0\n",
      "Tenure               0\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Geography_Germany    0\n",
      "Geography_Spain      0\n",
      "Gender_Male          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking for missing values in the training and validation sets \n",
    "print(X_train.isnull().sum())\n",
    "print(X_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
      "       'Geography_Germany', 'Geography_Spain', 'Gender_Male'],\n",
      "      dtype='object')\n",
      "Index(['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
      "       'Geography_Germany', 'Geography_Spain', 'Gender_Male'],\n",
      "      dtype='object')\n",
      "Index(['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
      "       'Geography_Germany', 'Geography_Spain', 'Gender_Male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the columns in X_train, X_val, and X_test\n",
    "print(X_train.columns)\n",
    "print(X_val.columns)\n",
    "print(X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Outlier Treatment\n",
      "       CreditScore          Age       Tenure        Balance  NumOfProducts  \\\n",
      "count  4900.000000  4900.000000  4900.000000    4900.000000    4900.000000   \n",
      "mean    652.050204    38.616939     5.007755   76163.334218       1.529388   \n",
      "std      96.324914     9.734252     2.883168   62581.580333       0.574829   \n",
      "min     384.000000    18.000000     0.000000       0.000000       1.000000   \n",
      "25%     585.000000    32.000000     3.000000       0.000000       1.000000   \n",
      "50%     654.000000    37.000000     5.000000   95539.735000       1.000000   \n",
      "75%     719.000000    44.000000     7.000000  127900.490000       2.000000   \n",
      "max     850.000000    62.000000    10.000000  250898.090000       3.500000   \n",
      "\n",
      "       EstimatedSalary  \n",
      "count      4900.000000  \n",
      "mean     101179.728978  \n",
      "std       57482.040816  \n",
      "min          90.070000  \n",
      "25%       51978.417500  \n",
      "50%      101473.150000  \n",
      "75%      150684.552500  \n",
      "max      199970.740000  \n"
     ]
    }
   ],
   "source": [
    "# Apply outlier treatment again\n",
    "X_train_treated = treat_outliers_iqr(X_train.copy(), numerical_features)\n",
    "X_val_treated = treat_outliers_iqr(X_val.copy(), numerical_features)\n",
    "X_test_treated = treat_outliers_iqr(X_test.copy(), numerical_features)\n",
    "\n",
    "# Now you can display the mean and std\n",
    "print(\"\\nAfter Outlier Treatment\")\n",
    "print(X_train_treated[numerical_features].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'RowNumber' and 'CustomerId' from all datasets before scaling\n",
    "X_train = X_train.drop(columns=['RowNumber', 'CustomerId'], errors='ignore')\n",
    "X_val = X_val.drop(columns=['RowNumber', 'CustomerId'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['RowNumber', 'CustomerId'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializiing the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling training and validatiion data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Scaling the test data (ensure consitency)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLQMVCywT87j"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzDpHlsFT_QA"
   },
   "source": [
    "### Model Evaluation Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FayG94iciXVS"
   },
   "source": [
    "we are going to chose, F1-score for our evaluation because we have class imbalances,\n",
    "prevent False Positives (its costly and burns time ), and will ive us a better score\n",
    "\n",
    "When we opitimize the F1-score, we will have built a model that effectively , indentifies at-risk customers, enabling the bank to take proactive measures to retain them while minimizing  unnecessary intervention . \n",
    "\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model architecture usintg tf.keras.Sequential\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)), # use Input as the first layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'), # First Hidden Layer\n",
    "    tf.keras.layers.Dense(32, activation='relu'), # Second Hidden layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # Output Layer \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "735HwSYiDSf1"
   },
   "source": [
    "### Neural Network with SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "ScqNP3QjDSf3"
   },
   "outputs": [],
   "source": [
    "# define the learning rate schedule \n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer with the learning rate schedule \n",
    "sgd_optimizer = SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with SGD optimizer \n",
    "model.compile(optimizer=sgd_optimizer,\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "CreditScore            int64\n",
      "Age                    int64\n",
      "Tenure                 int64\n",
      "Balance              float64\n",
      "NumOfProducts          int64\n",
      "HasCrCard              int64\n",
      "IsActiveMember         int64\n",
      "EstimatedSalary      float64\n",
      "Geography_Germany       bool\n",
      "Geography_Spain         bool\n",
      "Gender_Male             bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_scaled))  # To check the type of the object\n",
    "\n",
    "# To check the types of the original features before scaling\n",
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 11)\n",
      "(2100, 11)\n",
      "(3000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_val_scaled.shape)\n",
    "print(X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the test data has the same columns as the training and validation data\n",
    "X_test_scaled = X_test_scaled[:, :11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 11)\n",
      "(2100, 11)\n",
      "(3000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)  # (4900, 11)\n",
    "print(X_val_scaled.shape)    # (2100, 11)\n",
    "print(X_test_scaled.shape)   # (3000, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.6114 - val_accuracy: 0.7924 - val_loss: 0.4864\n",
      "Epoch 2/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7932 - loss: 0.4835 - val_accuracy: 0.7933 - val_loss: 0.4623\n",
      "Epoch 3/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8071 - loss: 0.4424 - val_accuracy: 0.8000 - val_loss: 0.4476\n",
      "Epoch 4/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8042 - loss: 0.4423 - val_accuracy: 0.8086 - val_loss: 0.4375\n",
      "Epoch 5/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8032 - loss: 0.4448 - val_accuracy: 0.8152 - val_loss: 0.4301\n",
      "Epoch 6/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8168 - loss: 0.4187 - val_accuracy: 0.8229 - val_loss: 0.4246\n",
      "Epoch 7/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8169 - loss: 0.4219 - val_accuracy: 0.8252 - val_loss: 0.4201\n",
      "Epoch 8/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8243 - loss: 0.4067 - val_accuracy: 0.8281 - val_loss: 0.4165\n",
      "Epoch 9/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8208 - loss: 0.4097 - val_accuracy: 0.8314 - val_loss: 0.4127\n",
      "Epoch 10/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.3941 - val_accuracy: 0.8357 - val_loss: 0.4098\n",
      "Epoch 11/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8313 - loss: 0.3979 - val_accuracy: 0.8395 - val_loss: 0.4051\n",
      "Epoch 12/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.3883 - val_accuracy: 0.8386 - val_loss: 0.4016\n",
      "Epoch 13/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.4001 - val_accuracy: 0.8414 - val_loss: 0.3986\n",
      "Epoch 14/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.3867 - val_accuracy: 0.8419 - val_loss: 0.3956\n",
      "Epoch 15/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3797 - val_accuracy: 0.8395 - val_loss: 0.3928\n",
      "Epoch 16/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3824 - val_accuracy: 0.8386 - val_loss: 0.3887\n",
      "Epoch 17/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8481 - loss: 0.3628 - val_accuracy: 0.8400 - val_loss: 0.3857\n",
      "Epoch 18/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 0.3612 - val_accuracy: 0.8433 - val_loss: 0.3842\n",
      "Epoch 19/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8469 - loss: 0.3690 - val_accuracy: 0.8452 - val_loss: 0.3807\n",
      "Epoch 20/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8554 - loss: 0.3553 - val_accuracy: 0.8471 - val_loss: 0.3787\n",
      "Epoch 21/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3476 - val_accuracy: 0.8481 - val_loss: 0.3762\n",
      "Epoch 22/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8547 - loss: 0.3594 - val_accuracy: 0.8462 - val_loss: 0.3748\n",
      "Epoch 23/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8565 - loss: 0.3549 - val_accuracy: 0.8457 - val_loss: 0.3729\n",
      "Epoch 24/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8552 - loss: 0.3395 - val_accuracy: 0.8471 - val_loss: 0.3714\n",
      "Epoch 25/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8495 - loss: 0.3566 - val_accuracy: 0.8476 - val_loss: 0.3701\n",
      "Epoch 26/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8558 - loss: 0.3434 - val_accuracy: 0.8486 - val_loss: 0.3685\n",
      "Epoch 27/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3444 - val_accuracy: 0.8471 - val_loss: 0.3676\n",
      "Epoch 28/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8553 - loss: 0.3467 - val_accuracy: 0.8476 - val_loss: 0.3671\n",
      "Epoch 29/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8644 - loss: 0.3315 - val_accuracy: 0.8462 - val_loss: 0.3680\n",
      "Epoch 30/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8566 - loss: 0.3483 - val_accuracy: 0.8519 - val_loss: 0.3660\n",
      "Epoch 31/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3391 - val_accuracy: 0.8471 - val_loss: 0.3652\n",
      "Epoch 32/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8588 - loss: 0.3371 - val_accuracy: 0.8476 - val_loss: 0.3646\n",
      "Epoch 33/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8477 - loss: 0.3546 - val_accuracy: 0.8510 - val_loss: 0.3639\n",
      "Epoch 34/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.3316 - val_accuracy: 0.8495 - val_loss: 0.3645\n",
      "Epoch 35/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8713 - loss: 0.3282 - val_accuracy: 0.8476 - val_loss: 0.3635\n",
      "Epoch 36/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8627 - loss: 0.3396 - val_accuracy: 0.8467 - val_loss: 0.3631\n",
      "Epoch 37/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8675 - loss: 0.3217 - val_accuracy: 0.8476 - val_loss: 0.3638\n",
      "Epoch 38/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3331 - val_accuracy: 0.8476 - val_loss: 0.3626\n",
      "Epoch 39/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.3301 - val_accuracy: 0.8476 - val_loss: 0.3623\n",
      "Epoch 40/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8622 - loss: 0.3259 - val_accuracy: 0.8486 - val_loss: 0.3625\n",
      "Epoch 41/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8626 - loss: 0.3326 - val_accuracy: 0.8476 - val_loss: 0.3623\n",
      "Epoch 42/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8635 - loss: 0.3365 - val_accuracy: 0.8486 - val_loss: 0.3621\n",
      "Epoch 43/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3257 - val_accuracy: 0.8510 - val_loss: 0.3620\n",
      "Epoch 44/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8668 - loss: 0.3215 - val_accuracy: 0.8476 - val_loss: 0.3614\n",
      "Epoch 45/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8743 - loss: 0.3065 - val_accuracy: 0.8448 - val_loss: 0.3626\n",
      "Epoch 46/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8565 - loss: 0.3386 - val_accuracy: 0.8476 - val_loss: 0.3605\n",
      "Epoch 47/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3288 - val_accuracy: 0.8500 - val_loss: 0.3607\n",
      "Epoch 48/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3418 - val_accuracy: 0.8481 - val_loss: 0.3612\n",
      "Epoch 49/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8648 - loss: 0.3262 - val_accuracy: 0.8524 - val_loss: 0.3616\n",
      "Epoch 50/50\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8708 - loss: 0.3142 - val_accuracy: 0.8438 - val_loss: 0.3606\n"
     ]
    }
   ],
   "source": [
    "# fit the model to the training data\n",
    "history = model.fit(X_train_scaled ,y_train,epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step\n",
      "F1 Score: 0.5761658031088083\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert probabilities to binary outcomes (since F1 score is for classification tasks)\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred_bin)\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2313  103]\n",
      " [ 306  278]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_bin)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygzPHkE_Anaw"
   },
   "source": [
    "## Model Performance Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE a leearning rate reduction callback\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss',factor=0.5, patience=5, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.3120 - val_accuracy: 0.8505 - val_loss: 0.3602\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3222 - val_accuracy: 0.8481 - val_loss: 0.3603\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8723 - loss: 0.3264 - val_accuracy: 0.8448 - val_loss: 0.3605\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.3233 - val_accuracy: 0.8481 - val_loss: 0.3601\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3320 - val_accuracy: 0.8500 - val_loss: 0.3599\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8760 - loss: 0.3177 - val_accuracy: 0.8500 - val_loss: 0.3601\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3136 - val_accuracy: 0.8500 - val_loss: 0.3601\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3225 - val_accuracy: 0.8481 - val_loss: 0.3600\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8613 - loss: 0.3353 - val_accuracy: 0.8514 - val_loss: 0.3600\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3193 - val_accuracy: 0.8490 - val_loss: 0.3599\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8723 - loss: 0.3305 - val_accuracy: 0.8481 - val_loss: 0.3599\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8680 - loss: 0.3342 - val_accuracy: 0.8481 - val_loss: 0.3600\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.3183 - val_accuracy: 0.8476 - val_loss: 0.3598\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3401 - val_accuracy: 0.8500 - val_loss: 0.3598\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3336 - val_accuracy: 0.8471 - val_loss: 0.3602\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3336 - val_accuracy: 0.8490 - val_loss: 0.3599\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.3280 - val_accuracy: 0.8476 - val_loss: 0.3598\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3291 - val_accuracy: 0.8486 - val_loss: 0.3600\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3333 - val_accuracy: 0.8500 - val_loss: 0.3596\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3163 - val_accuracy: 0.8514 - val_loss: 0.3596\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.3255 - val_accuracy: 0.8490 - val_loss: 0.3595\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3225 - val_accuracy: 0.8505 - val_loss: 0.3595\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3250 - val_accuracy: 0.8490 - val_loss: 0.3597\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.3274 - val_accuracy: 0.8486 - val_loss: 0.3597\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3290 - val_accuracy: 0.8486 - val_loss: 0.3598\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3203 - val_accuracy: 0.8471 - val_loss: 0.3595\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3385 - val_accuracy: 0.8510 - val_loss: 0.3597\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.3135 - val_accuracy: 0.8519 - val_loss: 0.3597\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.3185 - val_accuracy: 0.8505 - val_loss: 0.3597\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.3105 - val_accuracy: 0.8495 - val_loss: 0.3595\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.3022 - val_accuracy: 0.8486 - val_loss: 0.3595\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3284 - val_accuracy: 0.8495 - val_loss: 0.3595\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.3240 - val_accuracy: 0.8495 - val_loss: 0.3594\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8668 - loss: 0.3245 - val_accuracy: 0.8476 - val_loss: 0.3594\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.3233 - val_accuracy: 0.8476 - val_loss: 0.3594\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.3122 - val_accuracy: 0.8476 - val_loss: 0.3594\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3211 - val_accuracy: 0.8495 - val_loss: 0.3595\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.3213 - val_accuracy: 0.8510 - val_loss: 0.3594\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3212 - val_accuracy: 0.8486 - val_loss: 0.3594\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.3230 - val_accuracy: 0.8481 - val_loss: 0.3593\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.3387 - val_accuracy: 0.8500 - val_loss: 0.3593\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8647 - loss: 0.3149 - val_accuracy: 0.8495 - val_loss: 0.3593\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3208 - val_accuracy: 0.8505 - val_loss: 0.3592\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3188 - val_accuracy: 0.8490 - val_loss: 0.3591\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8639 - loss: 0.3240 - val_accuracy: 0.8495 - val_loss: 0.3592\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3183 - val_accuracy: 0.8514 - val_loss: 0.3593\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.3213 - val_accuracy: 0.8486 - val_loss: 0.3595\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3172 - val_accuracy: 0.8495 - val_loss: 0.3595\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3223 - val_accuracy: 0.8481 - val_loss: 0.3593\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.3162 - val_accuracy: 0.8486 - val_loss: 0.3594\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3285 - val_accuracy: 0.8486 - val_loss: 0.3594\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.3082 - val_accuracy: 0.8486 - val_loss: 0.3594\n",
      "Epoch 53/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3339 - val_accuracy: 0.8500 - val_loss: 0.3594\n",
      "Epoch 54/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.3237 - val_accuracy: 0.8481 - val_loss: 0.3595\n",
      "Epoch 55/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.3168 - val_accuracy: 0.8486 - val_loss: 0.3595\n",
      "Epoch 56/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.3164 - val_accuracy: 0.8490 - val_loss: 0.3595\n",
      "Epoch 57/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3176 - val_accuracy: 0.8481 - val_loss: 0.3594\n",
      "Epoch 58/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.3136 - val_accuracy: 0.8486 - val_loss: 0.3595\n",
      "Epoch 59/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8599 - loss: 0.3340 - val_accuracy: 0.8510 - val_loss: 0.3596\n",
      "Epoch 60/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.3037 - val_accuracy: 0.8490 - val_loss: 0.3596\n",
      "Epoch 61/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3228 - val_accuracy: 0.8481 - val_loss: 0.3593\n",
      "Epoch 62/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.3161 - val_accuracy: 0.8495 - val_loss: 0.3593\n",
      "Epoch 63/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.3056 - val_accuracy: 0.8495 - val_loss: 0.3595\n",
      "Epoch 64/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3125 - val_accuracy: 0.8486 - val_loss: 0.3595\n",
      "Epoch 65/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.3139 - val_accuracy: 0.8495 - val_loss: 0.3597\n",
      "Epoch 66/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3193 - val_accuracy: 0.8490 - val_loss: 0.3597\n",
      "Epoch 67/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3255 - val_accuracy: 0.8500 - val_loss: 0.3598\n",
      "Epoch 68/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3251 - val_accuracy: 0.8486 - val_loss: 0.3596\n",
      "Epoch 69/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.3030 - val_accuracy: 0.8490 - val_loss: 0.3597\n",
      "Epoch 70/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.3195 - val_accuracy: 0.8490 - val_loss: 0.3596\n",
      "Epoch 71/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3004 - val_accuracy: 0.8486 - val_loss: 0.3596\n",
      "Epoch 72/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8668 - loss: 0.3222 - val_accuracy: 0.8486 - val_loss: 0.3594\n",
      "Epoch 73/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.3127 - val_accuracy: 0.8495 - val_loss: 0.3596\n",
      "Epoch 74/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.3039 - val_accuracy: 0.8486 - val_loss: 0.3597\n",
      "Epoch 75/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.3157 - val_accuracy: 0.8490 - val_loss: 0.3598\n",
      "Epoch 76/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3137 - val_accuracy: 0.8471 - val_loss: 0.3602\n",
      "Epoch 77/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.3127 - val_accuracy: 0.8486 - val_loss: 0.3600\n",
      "Epoch 78/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3257 - val_accuracy: 0.8486 - val_loss: 0.3599\n",
      "Epoch 79/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3132 - val_accuracy: 0.8486 - val_loss: 0.3599\n",
      "Epoch 80/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3126 - val_accuracy: 0.8486 - val_loss: 0.3599\n",
      "Epoch 81/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.3107 - val_accuracy: 0.8467 - val_loss: 0.3603\n",
      "Epoch 82/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3366 - val_accuracy: 0.8490 - val_loss: 0.3599\n",
      "Epoch 83/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.3057 - val_accuracy: 0.8471 - val_loss: 0.3601\n",
      "Epoch 84/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3123 - val_accuracy: 0.8481 - val_loss: 0.3599\n",
      "Epoch 85/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.3118 - val_accuracy: 0.8471 - val_loss: 0.3601\n",
      "Epoch 86/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.3255 - val_accuracy: 0.8486 - val_loss: 0.3601\n",
      "Epoch 87/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.3143 - val_accuracy: 0.8481 - val_loss: 0.3602\n",
      "Epoch 88/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3169 - val_accuracy: 0.8471 - val_loss: 0.3601\n",
      "Epoch 89/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.3113 - val_accuracy: 0.8481 - val_loss: 0.3604\n",
      "Epoch 90/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.3113 - val_accuracy: 0.8476 - val_loss: 0.3604\n",
      "Epoch 91/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.3167 - val_accuracy: 0.8476 - val_loss: 0.3604\n",
      "Epoch 92/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.2949 - val_accuracy: 0.8471 - val_loss: 0.3606\n",
      "Epoch 93/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.3161 - val_accuracy: 0.8481 - val_loss: 0.3606\n",
      "Epoch 94/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3125 - val_accuracy: 0.8481 - val_loss: 0.3605\n",
      "Epoch 95/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.3187 - val_accuracy: 0.8462 - val_loss: 0.3610\n",
      "Epoch 96/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.3056 - val_accuracy: 0.8471 - val_loss: 0.3606\n",
      "Epoch 97/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.3155 - val_accuracy: 0.8486 - val_loss: 0.3607\n",
      "Epoch 98/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.3123 - val_accuracy: 0.8467 - val_loss: 0.3608\n",
      "Epoch 99/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8741 - loss: 0.3037 - val_accuracy: 0.8476 - val_loss: 0.3607\n",
      "Epoch 100/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.3080 - val_accuracy: 0.8471 - val_loss: 0.3610\n"
     ]
    }
   ],
   "source": [
    "# Adjust batch size and epochs\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64,\n",
    "                    validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step\n",
      "F1 Score: 0.5754527162977867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert probabilities to binary outcomes (since F1 score is for classification tasks)\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred_bin)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2292  124]\n",
      " [ 298  286]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_bin)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcEiT7Vyc6Y0"
   },
   "source": [
    "### Neural Network with Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "_5anPDAru0Vq"
   },
   "outputs": [],
   "source": [
    "# Define the model with Adam Optimizer \n",
    "\n",
    "\n",
    "model_adam = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Define the input shape here\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),  # Adding another layer with fewer neurons\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer\n",
    "model_adam.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add learning rate reduction\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 11)\n",
      "(2100, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  # Should be (n_samples, n_features)\n",
    "print(X_val.shape)    # Should be (n_samples, n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))  # Should return False\n",
    "print(np.any(np.isnan(X_val)))    # Should return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "X_val = np.array(X_val, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 2.2342 - val_accuracy: 0.7881 - val_loss: 3.6217 - learning_rate: 6.2500e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 3.4045 - val_accuracy: 0.6990 - val_loss: 1.5854 - learning_rate: 6.2500e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 2.3020 - val_accuracy: 0.7195 - val_loss: 1.7296 - learning_rate: 6.2500e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 2.0076 - val_accuracy: 0.6543 - val_loss: 3.8528 - learning_rate: 6.2500e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 2.2517 - val_accuracy: 0.4614 - val_loss: 2.6722 - learning_rate: 6.2500e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 2.5171 - val_accuracy: 0.5210 - val_loss: 4.7391 - learning_rate: 6.2500e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m56/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.6808 - loss: 2.8510\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6893 - loss: 2.6607 - val_accuracy: 0.7890 - val_loss: 3.0816 - learning_rate: 6.2500e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 1.6354 - val_accuracy: 0.7633 - val_loss: 1.4785 - learning_rate: 3.1250e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 1.3392 - val_accuracy: 0.6324 - val_loss: 1.4946 - learning_rate: 3.1250e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 1.2807 - val_accuracy: 0.7171 - val_loss: 1.4244 - learning_rate: 3.1250e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 1.5267 - val_accuracy: 0.7857 - val_loss: 2.2573 - learning_rate: 3.1250e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7478 - loss: 1.3015 - val_accuracy: 0.6933 - val_loss: 1.1412 - learning_rate: 3.1250e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 1.1391 - val_accuracy: 0.7419 - val_loss: 1.4029 - learning_rate: 3.1250e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 1.1900 - val_accuracy: 0.7443 - val_loss: 1.1754 - learning_rate: 3.1250e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 1.2907 - val_accuracy: 0.7300 - val_loss: 1.0869 - learning_rate: 3.1250e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 1.0664 - val_accuracy: 0.7095 - val_loss: 1.3621 - learning_rate: 3.1250e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 1.1974 - val_accuracy: 0.6629 - val_loss: 1.2883 - learning_rate: 3.1250e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7451 - loss: 1.1882 - val_accuracy: 0.6048 - val_loss: 1.8626 - learning_rate: 3.1250e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 1.4768 - val_accuracy: 0.7895 - val_loss: 3.4491 - learning_rate: 3.1250e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m58/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7180 - loss: 1.7091\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 1.5966 - val_accuracy: 0.4252 - val_loss: 4.0972 - learning_rate: 3.1250e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6943 - loss: 1.9778 - val_accuracy: 0.6271 - val_loss: 1.3197 - learning_rate: 1.5625e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.9184 - val_accuracy: 0.7762 - val_loss: 1.2243 - learning_rate: 1.5625e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7468 - loss: 1.0428 - val_accuracy: 0.7629 - val_loss: 0.9828 - learning_rate: 1.5625e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.8962 - val_accuracy: 0.7486 - val_loss: 1.0459 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7508 - loss: 0.8686 - val_accuracy: 0.7048 - val_loss: 1.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7529 - loss: 0.9190 - val_accuracy: 0.7114 - val_loss: 1.0786 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7554 - loss: 0.8614 - val_accuracy: 0.7567 - val_loss: 0.9504 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.9767 - val_accuracy: 0.7800 - val_loss: 1.2230 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 1.0511 - val_accuracy: 0.7619 - val_loss: 1.0023 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7634 - loss: 0.8267 - val_accuracy: 0.7481 - val_loss: 0.9241 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7544 - loss: 0.8298 - val_accuracy: 0.7476 - val_loss: 0.9215 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.8581 - val_accuracy: 0.6919 - val_loss: 0.9726 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.8664 - val_accuracy: 0.7733 - val_loss: 1.0631 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.9742 - val_accuracy: 0.7490 - val_loss: 0.8820 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 1.1400 - val_accuracy: 0.7024 - val_loss: 1.1170 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.8997 - val_accuracy: 0.7800 - val_loss: 1.4207 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7446 - loss: 1.1036 - val_accuracy: 0.7100 - val_loss: 1.0142 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7471 - loss: 1.0145 - val_accuracy: 0.7571 - val_loss: 0.9780 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m58/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7167 - loss: 1.0667\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 1.0744 - val_accuracy: 0.7571 - val_loss: 0.9660 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.8106 - val_accuracy: 0.7676 - val_loss: 1.0111 - learning_rate: 7.8125e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7477 - loss: 0.8681 - val_accuracy: 0.6090 - val_loss: 1.2843 - learning_rate: 7.8125e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7441 - loss: 0.8092 - val_accuracy: 0.7010 - val_loss: 0.9511 - learning_rate: 7.8125e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.7913 - val_accuracy: 0.6214 - val_loss: 1.1150 - learning_rate: 7.8125e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.8406 - val_accuracy: 0.7562 - val_loss: 0.8649 - learning_rate: 7.8125e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7411 - loss: 0.8257 - val_accuracy: 0.7590 - val_loss: 0.8684 - learning_rate: 7.8125e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7505 - loss: 0.7821 - val_accuracy: 0.6824 - val_loss: 1.1083 - learning_rate: 7.8125e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.7961 - val_accuracy: 0.7214 - val_loss: 0.8965 - learning_rate: 7.8125e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.7953 - val_accuracy: 0.7010 - val_loss: 0.9598 - learning_rate: 7.8125e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m58/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7440 - loss: 0.8897\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.8743 - val_accuracy: 0.7548 - val_loss: 0.9423 - learning_rate: 7.8125e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.7782 - val_accuracy: 0.7519 - val_loss: 0.8358 - learning_rate: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with ReduceLROnPlateau for learning rate adjustment\n",
    "history_adam = model_adam.fit(X_train, y_train, epochs=50, batch_size=64,\n",
    "                              validation_data=(X_val, y_val),\n",
    "                              callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-86J6fRu0vu"
   },
   "source": [
    "### Neural Network with Adam Optimizer and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "2WkE_mqIu0SP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nobody\\anaconda3\\envs\\crewai\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6699 - loss: 3020.4026 - val_accuracy: 0.7440 - val_loss: 108.8361\n",
      "Epoch 2/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 680.1493 - val_accuracy: 0.6547 - val_loss: 30.0094\n",
      "Epoch 3/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 206.6677 - val_accuracy: 0.8053 - val_loss: 1.4903\n",
      "Epoch 4/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6848 - loss: 55.7342 - val_accuracy: 0.6197 - val_loss: 0.7979\n",
      "Epoch 5/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 27.3855 - val_accuracy: 0.8053 - val_loss: 0.6183\n",
      "Epoch 6/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 10.2121 - val_accuracy: 0.8053 - val_loss: 0.5980\n",
      "Epoch 7/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 10.2715 - val_accuracy: 0.8053 - val_loss: 0.5825\n",
      "Epoch 8/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 5.6852 - val_accuracy: 0.8053 - val_loss: 0.5819\n",
      "Epoch 9/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 6.9253 - val_accuracy: 0.8053 - val_loss: 0.5502\n",
      "Epoch 10/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7561 - loss: 3.8844 - val_accuracy: 0.8053 - val_loss: 0.5398\n",
      "Epoch 11/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7601 - loss: 3.1648 - val_accuracy: 0.8053 - val_loss: 0.5308\n",
      "Epoch 12/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 3.4797 - val_accuracy: 0.8053 - val_loss: 0.5228\n",
      "Epoch 13/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7605 - loss: 1.4861 - val_accuracy: 0.8053 - val_loss: 0.5160\n",
      "Epoch 14/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7554 - loss: 1.6749 - val_accuracy: 0.8053 - val_loss: 0.5104\n",
      "Epoch 15/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 1.6446 - val_accuracy: 0.8053 - val_loss: 0.5062\n",
      "Epoch 16/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 1.8502 - val_accuracy: 0.8053 - val_loss: 0.5033\n",
      "Epoch 17/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 1.4353 - val_accuracy: 0.8053 - val_loss: 0.5006\n",
      "Epoch 18/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 1.1112 - val_accuracy: 0.8053 - val_loss: 0.4992\n",
      "Epoch 19/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 1.6834 - val_accuracy: 0.8053 - val_loss: 0.4978\n",
      "Epoch 20/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.8741 - val_accuracy: 0.8053 - val_loss: 0.4966\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer and first hidden layer with Dropout\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(0.2))  # Dropout with 20% rate\n",
    "    \n",
    "    # Second hidden layer with Dropout\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))  # Dropout with 30% rate\n",
    "    \n",
    "    # Output layer (for binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model using Adam optimizer\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1Hav_XNu6ro"
   },
   "source": [
    "### Neural Network with Balanced Data (by applying SMOTE) and SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "vAHO1_vYu0DN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nobody\\anaconda3\\envs\\crewai\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5033 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4894 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4944 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5008 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5037 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4984 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5026 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4974 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5062 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5026 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4998 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4946 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4900 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4939 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4980 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5002 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4937 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4954 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5017 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5043 - loss: nan - val_accuracy: 0.8053 - val_loss: nan\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8025 - loss: nan\n",
      "Test Loss: nan\n",
      "Test Accuracy: 0.8053\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Step 1: Apply SMOTE to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Define the model with SGD optimizer\n",
    "def create_sgd_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer and first hidden layer with Dropout\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train_balanced.shape[1]))\n",
    "    model.add(Dropout(0.2))  # Dropout with 20% rate\n",
    "    \n",
    "    # Second hidden layer with Dropout\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))  # Dropout with 30% rate\n",
    "    \n",
    "    # Output layer (for binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model using SGD optimizer\n",
    "    sgd_optimizer = SGD(learning_rate=0.01)\n",
    "    model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "sgd_model = create_sgd_model()\n",
    "\n",
    "# Step 3: Train the model on the balanced dataset using SGD optimizer\n",
    "history_sgd = sgd_model.fit(X_train_balanced, y_train_balanced, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = sgd_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFhOUq6au-xp"
   },
   "source": [
    "### Neural Network with Balanced Data (by applying SMOTE) and Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "8egmXgW0u-Q0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nobody\\anaconda3\\envs\\crewai\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 2581.8430 - val_accuracy: 0.7607 - val_loss: 5.8048\n",
      "Epoch 2/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5214 - loss: 88.5424 - val_accuracy: 0.4817 - val_loss: 1.1175\n",
      "Epoch 3/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4985 - loss: 15.3281 - val_accuracy: 0.6537 - val_loss: 0.6359\n",
      "Epoch 4/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5149 - loss: 6.2231 - val_accuracy: 0.7303 - val_loss: 0.7318\n",
      "Epoch 5/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4986 - loss: 3.8658 - val_accuracy: 0.8053 - val_loss: 0.6858\n",
      "Epoch 6/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4899 - loss: 3.6277 - val_accuracy: 0.8053 - val_loss: 0.6909\n",
      "Epoch 7/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4943 - loss: 2.3022 - val_accuracy: 0.8053 - val_loss: 0.6912\n",
      "Epoch 8/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4974 - loss: 1.4446 - val_accuracy: 0.1953 - val_loss: 0.6949\n",
      "Epoch 9/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5044 - loss: 1.9130 - val_accuracy: 0.1953 - val_loss: 0.6936\n",
      "Epoch 10/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4947 - loss: 1.4147 - val_accuracy: 0.8053 - val_loss: 0.6921\n",
      "Epoch 11/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5015 - loss: 0.8005 - val_accuracy: 0.8053 - val_loss: 0.6896\n",
      "Epoch 12/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5083 - loss: 1.5986 - val_accuracy: 0.1953 - val_loss: 0.6936\n",
      "Epoch 13/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4932 - loss: 0.8142 - val_accuracy: 0.8053 - val_loss: 0.6915\n",
      "Epoch 14/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5009 - loss: 1.0461 - val_accuracy: 0.1953 - val_loss: 0.6936\n",
      "Epoch 15/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4975 - loss: 0.7696 - val_accuracy: 0.1953 - val_loss: 0.6941\n",
      "Epoch 16/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4875 - loss: 0.9129 - val_accuracy: 0.1953 - val_loss: 0.6932\n",
      "Epoch 17/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4962 - loss: 1.1894 - val_accuracy: 0.1953 - val_loss: 0.6956\n",
      "Epoch 18/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4894 - loss: 0.8628 - val_accuracy: 0.1953 - val_loss: 0.6940\n",
      "Epoch 19/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5004 - loss: 0.9809 - val_accuracy: 0.1953 - val_loss: 0.6928\n",
      "Epoch 20/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5097 - loss: 0.7222 - val_accuracy: 0.8053 - val_loss: 0.6925\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.8025 - loss: 0.6923\n",
      "Test Loss: 0.6925\n",
      "Test Accuracy: 0.8053\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the model with Adam optimizer\n",
    "def create_adam_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer and first hidden layer with Dropout\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train_balanced.shape[1]))\n",
    "    model.add(Dropout(0.2))  # Dropout with 20% rate\n",
    "    \n",
    "    # Second hidden layer with Dropout\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))  # Dropout with 30% rate\n",
    "    \n",
    "    # Output layer (for binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model using Adam optimizer\n",
    "    adam_optimizer = Adam(learning_rate=0.001)  # You can try different learning rates\n",
    "    model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "adam_model = create_adam_model()\n",
    "\n",
    "# Step 3: Train the model on the balanced dataset using Adam optimizer\n",
    "history_adam = adam_model.fit(X_train_balanced, y_train_balanced, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = adam_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTSK-_5YvBIR"
   },
   "source": [
    "### Neural Network with Balanced Data (by applying SMOTE), Adam Optimizer, and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "3Jqa4h2yuuE7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5189 - loss: 3670.9299 - val_accuracy: 0.2623 - val_loss: 47.4221 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 234.5527 - val_accuracy: 0.6480 - val_loss: 2.0781 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4974 - loss: 12.3207 - val_accuracy: 0.1947 - val_loss: 1.7441 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4928 - loss: 4.4599 - val_accuracy: 0.1947 - val_loss: 1.7424 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5103 - loss: 3.7646 - val_accuracy: 0.1947 - val_loss: 1.7392 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5090 - loss: 2.1822 - val_accuracy: 0.1947 - val_loss: 1.7352 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4829 - loss: 2.0067 - val_accuracy: 0.8053 - val_loss: 1.7290 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4942 - loss: 1.8362 - val_accuracy: 0.1947 - val_loss: 1.7242 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5087 - loss: 1.8397 - val_accuracy: 0.8053 - val_loss: 1.7184 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5021 - loss: 1.9634 - val_accuracy: 0.1947 - val_loss: 1.7142 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4908 - loss: 2.5929 - val_accuracy: 0.1947 - val_loss: 1.7136 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5019 - loss: 2.0135 - val_accuracy: 0.1947 - val_loss: 1.7130 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5039 - loss: 1.8432 - val_accuracy: 0.1947 - val_loss: 1.7122 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: 1.8780 - val_accuracy: 0.1947 - val_loss: 1.7111 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5056 - loss: 1.8052 - val_accuracy: 0.1947 - val_loss: 1.7099 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5060 - loss: 1.7764 - val_accuracy: 0.1947 - val_loss: 1.7089 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5021 - loss: 1.7538 - val_accuracy: 0.1947 - val_loss: 1.7073 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4925 - loss: 1.8778 - val_accuracy: 0.1947 - val_loss: 1.7061 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5124 - loss: 1.7347 - val_accuracy: 0.1947 - val_loss: 1.7045 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4935 - loss: 1.7187 - val_accuracy: 0.1947 - val_loss: 1.7026 - learning_rate: 1.0000e-04\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1975 - loss: 1.7026\n",
      "Test Loss: 1.7026\n",
      "Test Accuracy: 0.1947\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Apply SMOTE to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Learning rate scheduler function\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "# Step 3: Define the model with Adam optimizer, Dropout, and L2 regularization\n",
    "def create_regularized_adam_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer (use Input shape to avoid the warning)\n",
    "    model.add(Input(shape=(X_train_balanced.shape[1],)))\n",
    "    \n",
    "    # First hidden layer with L2 regularization and Dropout\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.3))  # Dropout with 30% rate\n",
    "    \n",
    "    # Second hidden layer with L2 regularization and Dropout\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.4))  # Dropout with 40% rate\n",
    "    \n",
    "    # Output layer (for binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model using Adam optimizer\n",
    "    adam_optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Step 4: Create the model\n",
    "adam_dropout_model = create_regularized_adam_model()\n",
    "\n",
    "# Step 5: Set up the learning rate scheduler\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Step 6: Train the model with the balanced dataset using Adam optimizer, Dropout, and Learning Rate Scheduler\n",
    "history_adam_dropout = adam_dropout_model.fit(\n",
    "    X_train_balanced, y_train_balanced,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[lr_scheduler]\n",
    ")\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "loss, accuracy = adam_dropout_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srfZVuMKc6Y_"
   },
   "source": [
    "## Model Performance Comparison and Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE1iHOqqOEmV"
   },
   "source": [
    "## Actionable Insights and Business Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouNNiEhUdhZL"
   },
   "source": [
    "*\n",
    "Proactive Retention Strategies: For customers identified as high-risk, the bank should initiate proactive retention strategies, such as personalized communication (e.g., offering better loan terms, personalized financial advice, or exclusive rewards) to increase customer satisfaction and reduce churn.\n",
    "\n",
    "Personalized Offers: The bank should design personalized retention offers based on insights from the model. For instance, offering discounted services or customized plans for customers whose patterns indicate a likelihood of churn can improve customer loyalty.\n",
    "\n",
    "Customer Experience Improvement: Based on the features driving churn, invest in improving the customer experience. This might involve upgrading customer support, streamlining mobile banking, or introducing more engaging features based on user preferences identified in the model.\n",
    "\n",
    "Optimizing Marketing Spend: Direct marketing efforts more efficiently by focusing on high-risk customers identified by the model. This allows the bank to allocate marketing resources where they can have the highest impact.\n",
    "\n",
    "Loyalty Programs: Enhance or introduce new loyalty programs for long-term customers who are likely to churn due to dissatisfaction or competition. Offer rewards, discounts, or benefits to keep customers engaged.\n",
    "\n",
    "By implementing these strategies, the bank can reduce churn rates, improve customer retention, and ultimately increase customer lifetime value (CLTV), leading to higher revenue and a stronger customer base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R23W-K3CmM9"
   },
   "source": [
    "<font size=6 color='blue'>Power Ahead</font>\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Q__obHNhdHtV",
    "WSyQJZSAaPA3",
    "s749lpTNaRkN",
    "Tsb28swdaVAs",
    "FHHrSIl4c6Yn",
    "z7ubXtC8HUOA",
    "eRxrJ2MHd_Sf",
    "W036jsgwRdVN",
    "nSFkV8KJiZSv",
    "OlHTHF4glMxS",
    "CUXPaUwZHUO8",
    "1nEEjgwleiMv",
    "wgpx0xlSTlzN",
    "qlSyq5fNHUPp",
    "ZLQMVCywT87j",
    "SzDpHlsFT_QA",
    "735HwSYiDSf1",
    "ygzPHkE_Anaw",
    "EcEiT7Vyc6Y0",
    "I-86J6fRu0vu",
    "m1Hav_XNu6ro",
    "sFhOUq6au-xp",
    "srfZVuMKc6Y_",
    "XE1iHOqqOEmV"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
